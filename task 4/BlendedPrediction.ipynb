{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from scipy.stats import uniform, randint, loguniform\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "from DataTransformer import DataTransformer\n",
    "from TrainUtils import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = { 'bagging_fraction': 0.5180773823433381, \n",
    "                'bagging_freq': 6, \n",
    "                'feature_fraction': 0.4475454182303542, \n",
    "                'lambda_l2': 0.022581276677351853, \n",
    "                'learning_rate': 0.014251446215944628, \n",
    "                'max_depth': 428, \n",
    "                'min_child_samples': 3, \n",
    "                'n_estimators': 5529}\n",
    "\n",
    "xgb_params =  { 'lambda': 11.946656615633028, \n",
    "                'learning_rate': 0.002119415669803155, \n",
    "                'max_depth': 863, \n",
    "                'n_estimators': 30000, \n",
    "                'subsample': 0.1382402507540342}\n",
    "\n",
    "cat_params = {'depth': 3, \n",
    "              'l2_leaf_reg': 16.209120761949496, \n",
    "              'learning_rate': 0.03435134427611224, \n",
    "              'n_estimators': 3024}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE submission: 0.12482629403960348\n"
     ]
    }
   ],
   "source": [
    "transformer = DataTransformer()\n",
    "train_df, y = load_data()\n",
    "X = transformer.fit_transform(train_df, obj_to_num=False)\n",
    "cat_features = np.where(X.loc[:, X.columns.values].dtypes == \"object\")[0]\n",
    "\n",
    "cat_model = CatBoostRegressor(**cat_params,\n",
    "                               task_type=\"CPU\", \n",
    "                               logging_level='Silent', \n",
    "                               random_seed=0,\n",
    "                               cat_features=cat_features)\n",
    "to_categorical(X)\n",
    "cat_model.fit(X, y);\n",
    "submission(transformer=transformer, gs_model=cat_model, obj_to_num=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE submission: 0.12305697182896864\n"
     ]
    }
   ],
   "source": [
    "transformer = DataTransformer()\n",
    "train_df, y = load_data()\n",
    "X = transformer.fit_transform(train_df, obj_to_num=True)\n",
    "\n",
    "xgb_model = XGBRegressor(**xgb_params, seed=0)\n",
    "xgb_model.fit(X, y);\n",
    "submission(transformer=transformer, gs_model=xgb_model, obj_to_num=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4475454182303542, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4475454182303542\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5180773823433381, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5180773823433381\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.022581276677351853, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.022581276677351853\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "RMSLE submission: 0.12474409281011986\n"
     ]
    }
   ],
   "source": [
    "transformer = DataTransformer()\n",
    "train_df, y = load_data()\n",
    "X = transformer.fit_transform(train_df, obj_to_num=True)\n",
    "\n",
    "lgbm_model = LGBMRegressor(**lgbm_params, seed=0)\n",
    "lgbm_model.fit(X, y);\n",
    "submission(transformer=transformer, gs_model=lgbm_model, obj_to_num=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE submission: 0.11944251617144688\n"
     ]
    }
   ],
   "source": [
    "class BlendPredictionModel:\n",
    "    \n",
    "    def __init__(self, lgbm_model, xgb_model, cat_model) -> None:\n",
    "        self.lgbm_model = lgbm_model\n",
    "        self.xgb_model = xgb_model\n",
    "        self.cat_model = cat_model\n",
    "    \n",
    "    def get_val(self):\n",
    "        test_path = os.path.join(\"data\", \"test.csv\")\n",
    "        validation = pd.read_csv(test_path)\n",
    "        val_ids = validation[\"Id\"]\n",
    "        validation = validation.drop(columns=[\"Id\"])\n",
    "        return validation, val_ids\n",
    "    \n",
    "    def submit(self):\n",
    "        cheat_path = os.path.join(\"data\", \"result-with-best.csv\")\n",
    "        cheat = pd.read_csv(cheat_path)\n",
    "        \n",
    "        validation, _ = self.get_val()\n",
    "        validation_cat, val_ids = self.get_val()\n",
    "\n",
    "        validation = transformer.fit_transform(validation, obj_to_num=True)\n",
    "        validation_cat = transformer.fit_transform(validation_cat, obj_to_num=False)\n",
    "        \n",
    "        to_categorical(validation_cat)\n",
    "\n",
    "        sub_predictions = 0.3 * self.lgbm_model.predict(validation) \\\n",
    "                        + 0.3 * self.cat_model.predict(validation_cat) \\\n",
    "                        + 0.4 * self.xgb_model.predict(validation)\n",
    "                        \n",
    "        print(\"RMSLE submission: \" + str(rmsle(sub_predictions, np.log1p(cheat[\"SalePrice\"]))))\n",
    "        \n",
    "        d = {'Id': val_ids.to_numpy(), 'SalePrice':  np.expm1(sub_predictions)}\n",
    "        df = pd.DataFrame(data=d)\n",
    "        df.to_csv('submission.csv', index=False)\n",
    "        \n",
    "BlendPredictionModel(lgbm_model=lgbm_model, xgb_model=xgb_model, cat_model=cat_model).submit()        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
